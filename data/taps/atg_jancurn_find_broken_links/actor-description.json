{
    "id": "jancurn/find-broken-links",
    "url": "https://apify.com/jancurn/find-broken-links",
    "title": "\ud83d\udd17 Broken Link Checker \u00b7 Apify",
    "name": "Broken Link Checker",
    "pricing": "No credit card required",
    "description": "Crawls a website and finds broken links. Unlike other similar SEO analysis tools, the actor also reports broken URL #fragments. The results are stored in a JSON and HTML report.",
    "author_name": "Jan \u010curn",
    "maintained_by": "Maintained by Apify",
    "count_users": "408 users",
    "count_runs": "33.7k runs",
    "last_modified": "Modified 18 days ago",
    "categories": "SEO tools",
    "full_readme": "What does Broken Links Checker do?\n\nOur Broken Links Checker is an easy-to-use SEO tool to help you keep your UX and SEO score healthy, improve your website ranking, and prevent link rot.\n\nHow does it check for broken links?\n\nBroken Link Checker can crawl any website and do all of the following:\n\ngenerate a report containing an inspection of all links on the website or only broken links\nscan one or multiple websites simultaneously\neasily check domain and subdomains\nidentify broken link fragments\ngive you a neat report in your email inbox once the SEO inspection is complete\ninitiate a SEO check manually or automatically thanks to our powerful scheduling system\nHow much does it cost to run Broken Links Checker?\n\nUsing our basic plan, the scraper's run will cost you around USD 0.25 in Apify platform credits per 1,000 scraped results. For more details about the plans we offer, platform credits and usage, see the platform pricing page.\n\nHow to start Broken Links Checker\n\nBroken Links Checker is highly adaptable to your SEO requests and can scan your web pages quickly and regularly. To check a website for bad links, repeat the following steps:\n\nClick on Try for free.\nAdd one or more website URLs to start the audit from.\nEnable the Save only broken links button.\nAdd your email address to receive the full SEO report in your inbox.\nClick Run and wait for the data to be collected.\nOptional step: Schedule the tool to check the links automatically every month, week or specific time during the day.\n\nFor a more detailed instruction with visual aids of how to set up a broken links checker and why, see our step-by-step tutorial on checking for broken links.\n\nWhat's happening under the hood?\n\nBroken Links Checker will start the link check at a given URL and will crawl all linked pages under that website. So for example, if the crawler starts at https://www.example.com/something, then it will also crawl linked pages such as:\n\nhttps://www.example.com/something/index.html\nhttps://www.example.com/something/else\nhttps://www.example.com/something/even/more/deeper/file.html\n\nOn every checked page, the crawler will also analyze whether links to other pages are working or not. For example, if the page contains a link to https://www.example.com/another/page#anchor, the actor will open the inspected page https://www.example.com/another/page, check whether it loads correctly and then it also check if it contains the #anchor.\n\nInput options\n\nIf this actor is run on the Apify platform, our user-friendly UI will help you configure all the necessary and optional parameters of this scraper before running it. Our Broken Links Checker recognizes the following input fields:\n\nWebsite URL The initial URL to start the broken links inspection from.\n\nMax pages Use this field to set the maximum number of pages to be checked. If left empty, the number will be unlimited.\n\nNotification emails Add the email address to receive a notification after the crawler discovers all broken links.\n\nSave only broken links If set to true, you'll get only the broken links in the report. If set to false, the crawler will include into the report both broken and healthy links (not a CSV friendly option).\n\nCrawl subdomains If set to true, the crawler will search broken links not only on the main page but also in deeper subdomains.\n\nFor more technical details on the input, head over to the Input tab.\n\nInput example\n\nHere's an input example for checking the Apify Blog for bad links. We've enabled the crawler to check subdomains as well but limited the inspection to 1,000 pages.\n\n    {\n      \"baseUrl\": \"https://blog.apify.com\",\n      \"maxPages\": 1000,\n      \"notificationEmails\": [\n        \"your.email@apify.com\"\n      ],\n      \"saveOnlyBrokenLinks\": true,\n      \"crawlSubdomains\": true\n    }\nOutput\n\nOnce the links checker finishes the crawl, it will save a report of the broken links into your key-value store. You will find reports in two formats there:\n\nOUTPUT contains a machine-readable JSON report\nOUTPUT.html contains an easy-to-read HTML report\nOutput example as JSON\n\nHere's an example of dataset of a successful Broken Links Checker run. The error message is included in the report and can be found at the bottom of the example.\n\n[\n  {\n    \"url\": \"https://blog.apify.com\",\n    \"title\": \"Apify Blog: Web scraping and automation stories\",\n    \"links\": [\n      {\n        \"url\": \"https://apify.com/\",\n        \"normalizedUrl\": \"https://apify.com\",\n        \"httpStatus\": 200,\n        \"fragment\": \"\",\n        \"fragmentValid\": true,\n        \"crawled\": true\n      },\n      {\n        \"url\": \"https://apify.com/about\",\n        \"normalizedUrl\": \"https://apify.com/about\",\n        \"httpStatus\": 200,\n        \"fragment\": \"\",\n        \"fragmentValid\": true,\n        \"crawled\": true\n      },\n      {\n        \"url\": \"https://apify.com/jobs\",\n        \"normalizedUrl\": \"https://apify.com/jobs\",\n        \"httpStatus\": 200,\n        \"fragment\": \"\",\n        \"fragmentValid\": true,\n        \"crawled\": true\n      },\n      {\n        \"url\": \"https://apify.com/web-scraping\",\n        \"normalizedUrl\": \"https://apify.com/web-scraping\",\n        \"httpStatus\": null,\n        \"errorMessage\": \"Error: Navigation timed out after 120 seconds.\\n    at handleRequestTimeout (/home/myuser/node_modules/apify/build/crawlers/crawler_utils.js:19:11)\\n    at PuppeteerCrawler._handleNavigationTimeout (/home/myuser/node_modules/apify/build/crawlers/browser_crawler.js:418:54)\\n    at PuppeteerCrawler._handleNavigation (/home/myuser/node_modules/apify/build/crawlers/browser_crawler.js:401:18)\\n    at async PuppeteerCrawler._handleRequestFunction (/home/myuser/node_modules/apify/build/crawlers/browser_crawler.js:343:13)\\n    at async wrap (/home/myuser/node_modules/@apify/timeout/index.js:73:27)\",\n        \"fragment\": \"\",\n        \"fragmentValid\": true,\n        \"crawled\": true\n      },\n...\nOther SEO audit tools\n\nYou can find other free SEO tools in the Related actors tab: Web Page Analyzer, SEO Audit Tool, Google Search Results Scraper. You should also check out 5 powerful scrapers to add to your SEO tool kit.",
    "icon": "https://images.apifyusercontent.com/qjCm3P1NGzzoqgaZ41EXSRTeB5ISlEZVQNs8meOUbK0/rs:fill:92:92/aHR0cHM6Ly9hcGlmeS1pbWFnZS11cGxvYWRzLXByb2QuczMuYW1hem9uYXdzLmNvbS96a2ZXUWkzeVpXY2pxaFdoaS9tNm9zQkJUYlNQeHpXdVRnRi1icm9rZW5fbGluay5qcGc.webp",
    "author_url": "https://apify.com/jancurn",
    "author_avatar": "https://images.apifyusercontent.com/H3aKDtXiftLU9atk8wkogcJxXh993G46JwiHcTm5e2Y/rs:fill:192:192/aHR0cHM6Ly9hcGlmeS1pbWFnZS11cGxvYWRzLXByb2QuczMuYW1hem9uYXdzLmNvbS85ZkJIcTRGcEh4ZFdZN3I1Yy96VHY5d2NYZ1dwUkRZOUN2eC1NYXhpa180bWVzXzA2XzAyXzIwX18wMDguanBn.webp",
    "readme_summary": "Crawls a website and finds broken links. The results are stored in a JSON and HTML report. The actor can generate a report containing an inspection of all links on the website or only broken links. It can scan one or multiple websites simultaneously, check domain and subdomains, and identify broken link fragments. The actor can be run on the Apify platform and recognizes input fields such as Website URL, Max pages, Notification emails, Save only broken links, and Crawl subdomains. Once the links checker finishes the crawl, it saves a report of the broken links into the key-value store in JSON and HTML format."
}